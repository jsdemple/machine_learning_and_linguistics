{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaged Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for a homework assignment for Mans Hulden's Machine Learning and Linguistics Course Fall 2017. It is part of the CLASIC program (computational linguistics) at CU Boulder, an interdisciplinary program housed in the Computer Science Dept and the Linguistics Dept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:<br>\n",
    "The perceptron is an artificial neuron capable of linear classification. The data are restaurant reviews from three types of restaurants, Mexican, Italian, and Chinese. Our task is to classify which type of restaurant each review comes from. The features have already been extracted beforehand. This notebook includes the training and testing of this perceptron restaurant classifier.<br>\n",
    "Many of these operations could be done with packages like Numpy, and I could have used one of many well-made packages for training classifiers, but the aim of this project is to write, train, and test this algorithm from scratch. The only module imported is <i>random</i>.\n",
    "<br><br>\n",
    "Results:<br>\n",
    "With weight averaging implemented, the classifier performs around 89% accuracy and takes around 8-14 iterations to train. This is roughly a 1 percent improvement from the non-averaged perceptron before.<br>\n",
    "The dev set is used here to avoid overfitting the model to the training set. However, accuracy on the dev set seemed to increase with each iteration. Perhaps this would change if we had a larger training set.<br><br>\n",
    "Accuracy: 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Training Data\n",
    "train_raw = [line.strip() for line in open('./data/hw3data/restaurant_train.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Testing Data\n",
    "test_raw = [line.strip() for line in open('./data/hw3data/restaurant_test.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Dev Data\n",
    "dev_raw = [line.strip() for line in open('./data/hw3data/restaurant_dev.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the training data, test data, and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count of features\n",
    "feature_count = 9492\n",
    "\n",
    "# count of classes\n",
    "class_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_raw_data(raw_dataset, feature_count, class_count):\n",
    "    \"\"\"\n",
    "    Parse a list of feature vectors training_data with correct \n",
    "    label first from raw data\n",
    "    Ex. [[0, [0, 1, 1...]], [1, [1, 1, 0...]], [2, [1, 0, 1...]]]\n",
    "    \n",
    "    Input, list: lines from raw txt data\n",
    "    Returns, list: list of feature vectors with their labels first\n",
    "    Ex. [[0, [0, 1, 1...]], [1, [1, 1, 0...]], [2, [1, 0, 1...]]]\"\"\"\n",
    "    \n",
    "    # list of labels, feature vectors to be returned\n",
    "    cleaned_data = []\n",
    "    \n",
    "    # Extract each feature vector from the raw training data\n",
    "    for line in raw_dataset:\n",
    "        feature_vector_raw = []\n",
    "        feature_vector_raw = [pair for pair in line.split()]\n",
    "        # pop first item, this is the class\n",
    "        class_id = int(feature_vector_raw.pop(0))\n",
    "\n",
    "        feature_dict = {}\n",
    "        for fx in feature_vector_raw:\n",
    "            pair = [int(x) for x in fx.split(':')]\n",
    "            feature_dict[pair[0]] = pair[1]\n",
    "\n",
    "        # initialize vector as all zeros\n",
    "        empty_vec = [0] * feature_count  # total number of features\n",
    "\n",
    "        # populate the vector with ones for each feature\n",
    "        for key in feature_dict:\n",
    "            empty_vec[key] = feature_dict[key]\n",
    "        feature_vector = [class_id]\n",
    "        feature_vector.append(empty_vec)\n",
    "\n",
    "        # add the vector to the training/test/dev set total\n",
    "        cleaned_data.append(feature_vector)\n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = vectorize_raw_data(train_raw, feature_count=feature_count, class_count=class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_data = vectorize_raw_data(test_raw, feature_count=feature_count, class_count=class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_data = vectorize_raw_data(dev_raw, feature_count=feature_count, class_count=class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the weight vectors as all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = [[0] * feature_count] * class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of labels or classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = list(range(class_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the mathmatical functions that will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dotproduct(v1, v2):\n",
    "    \"\"\"\n",
    "    Get the dot product of two one-dimensional vectors\n",
    "    returns: dotproduct, int\n",
    "    \"\"\"\n",
    "    if len(v1) != len(v2):\n",
    "        return \"ERROR: Vectors must be the same length\"\n",
    "    zipped = list(zip(v1, v2))\n",
    "    return sum([i[0]*i[1] for i in zipped])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component Addition of Two Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Get the component sum of two one-dimensional vectors\n",
    "    returns: sum, int\n",
    "    \"\"\"\n",
    "    if len(v1) != len(v2):\n",
    "        return \"ERROR: Vectors must be the same length\"\n",
    "    zipped = list(zip(v1, v2))\n",
    "    return [i[0]+i[1] for i in zipped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component Subtraction of Two Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtract_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Get the component difference of two one-dimensional vectors\n",
    "    returns: difference, int\n",
    "    \"\"\"\n",
    "    if len(v1) != len(v2):\n",
    "        return \"ERROR: Vectors must be the same length\"\n",
    "    zipped = list(zip(v1, v2))\n",
    "    return [i[0]-i[1] for i in zipped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide a Vector by a single integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_vector(vec, denominator):\n",
    "    \"\"\"\n",
    "    Divide a vector by a single integer or fload\n",
    "    Returns list: returns a vector\n",
    "    \"\"\"\n",
    "    return [i / denominator for i in vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the index of the highest value in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_value_index(l):\n",
    "    max_value = max(l)\n",
    "    max_index = l.index(max_value)\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_three_class(fx,w):\n",
    "    \"\"\"\n",
    "    Returns the label with the highest dot product as the predicted label.\n",
    "    \n",
    "    Input fx: list. A feature vector \n",
    "    Input w: list of weight vectors\n",
    "    Returns: int. Predicted class label \n",
    "    \"\"\"\n",
    "    # get dot product of fx and each weight vector\n",
    "    dp0 = dotproduct(fx, w[0])\n",
    "    dp1 = dotproduct(fx, w[1])\n",
    "    dp2 = dotproduct(fx, w[2])\n",
    "    dotproducts = [dp0, dp1, dp2]\n",
    "    # check if all dot products are equal\n",
    "    if dp0 == dp1 == dp2:\n",
    "        return random.choice([0,1,2])\n",
    "    else:\n",
    "        return get_max_value_index(dotproducts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the averaged perceptron\n",
    "Checking the dev set after every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(test_or_dev, w):\n",
    "    # This function evaluates the accuracy of the model on \n",
    "    # either the testset or the devset# either the testset or the devset\n",
    "    errors = 0\n",
    "    dataset_size = len(test_or_dev)\n",
    "    for correct_label, fx in test_or_dev:\n",
    "        predicted_label = classify_three_class(fx, w)\n",
    "        if correct_label != predicted_label:\n",
    "            errors += 1\n",
    "    return (dataset_size - errors) / dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop - Train the data. Check against dev set after every iteration to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\n",
      "\n",
      "TRAIN\t| DEV\n",
      "------------------\n",
      "0.681 \t|  0.86\n",
      "0.9 \t|  0.908\n",
      "0.954 \t|  0.832\n",
      "0.973 \t|  0.84\n",
      "0.983 \t|  0.836\n",
      "0.987 \t|  0.892\n",
      "0.988 \t|  0.868\n",
      "1.0 \t|  0.868\n",
      "\n",
      "ITERATIONS: 8\n"
     ]
    }
   ],
   "source": [
    "errors = 1\n",
    "iterations = 0\n",
    "w_sum = w\n",
    "\n",
    "print('ACCURACY:\\n\\nTRAIN\\t| DEV\\n------------------')\n",
    "while errors > 0:\n",
    "    errors = 0\n",
    "    for correct_label, fx in training_data:\n",
    "        predicted_label = classify_three_class(fx, w)\n",
    "        if correct_label != predicted_label:\n",
    "            w[correct_label] = add_vectors(w[correct_label], fx)\n",
    "            w[predicted_label] = subtract_vectors(w[predicted_label], fx) # subtract features from it\n",
    "            errors += 1\n",
    "    # print('ERRORS:', errors)  # this number should go down\n",
    "    iterations += 1\n",
    "    # total sum of weight vectors for perceptron averaging\n",
    "    w_sum = [add_vectors(w_sum[i],w[i]) for i in range(class_count)]\n",
    "    \n",
    "    # check against the dev set\n",
    "    dev_eval = evaluate_accuracy(dev_data, w)\n",
    "    train_eval = (len(training_data) - errors) / len(training_data)\n",
    "    print(train_eval, '\\t| ', dev_eval)\n",
    "    \n",
    "# print accuracy table to watch as accuracy increases with each iteration\n",
    "# if dev accuracy starts to drop, halt training to avoid overfit\n",
    "print('\\nITERATIONS:', iterations)\n",
    "\n",
    "# after loop completes, compute the averaged weights\n",
    "w_avg = [divide_vector(w_sum[i], iterations) for i in range(class_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see a significant dip in accuracy on the dev set as we iterate. Accuracy acctually increases. So I will let the perceptron train until completion (at zero training errors in an iteration). If dev accuracy were to drop significantly we would halt the training before it reaches zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ACCURACY:\n",
    "\n",
    "# TRAIN\t| DEV\n",
    "# ------------------\n",
    "# 0.699 \t|  0.78\n",
    "# 0.894 \t|  0.868\n",
    "# 0.948 \t|  0.864\n",
    "# 0.972 \t|  0.88\n",
    "# 0.978 \t|  0.876\n",
    "# 0.99 \t|  0.876\n",
    "# 0.996 \t|  0.892\n",
    "# 0.993 \t|  0.892\n",
    "# 0.996 \t|  0.892\n",
    "# 0.998 \t|  0.892\n",
    "# 1.0 \t|  0.892\n",
    "\n",
    "# ITERATIONS: 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron Accuracy: 0.876 - 0.888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(testing_data, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged Perceptron Accuracy 0.892 - 0.894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(testing_data, w_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging the weights from each iteration improves accuracy by roughly 1 percent. I expected to see a decrease in accuracy on the dev set before the perceptron reached zero errors, but accuracy on the dev set seemed to increase with each iteration. Perhaps this would change if we had a larger training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_general",
   "language": "python",
   "name": "data_science_general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
